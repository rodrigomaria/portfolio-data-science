{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Detecção de Fraude em Cartões de Crédito.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodrigomariamorgao/portfolio_data_science/blob/master/Detec%C3%A7%C3%A3o_de_Fraude_em_Cart%C3%B5es_de_Cr%C3%A9dito.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC2BFMOKN1M7",
        "colab_type": "text"
      },
      "source": [
        "<img alt=\"BannerDataScience\" width=\"100%\" src=\"https://raw.githubusercontent.com/rodrigomariamorgao/portfolio_data_science/master/banner.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4kh4P2xp5T6",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# suprimir os warnings\n",
        "from warnings import simplefilter\n",
        "simplefilter(action='ignore', category=FutureWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IR56trFcPcC1",
        "colab_type": "text"
      },
      "source": [
        "# **Detecção de Fraudes em Cartões de Crédito**\n",
        "\n",
        "Neste projeto iremos abordar o problema das fraudes em cartões de crédito, uma das principais preocupações das instituições financeiras como bancos e *fintechs*. Apenas no Brasil cerca de **12,1 milhões de pessoas** já foram vítimas de algum tipo de fraude financeira no último ano. Traduzindo em valores, os golpes financeiros ultrapassaram a cifra de **R$ 1,8 bilhão de prejuízo** para os últimos 12 meses.\n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://www.creditooudebito.com/wp-content/uploads/2019/04/fraude-cartao.jpg\" width=\"60%\"></p>\n",
        "\n",
        "Dentre essas fraudes, as que envolvem cartões de crédito são de grande relevância, uma vez que a sua não-detecção acaretará em prejuízos consideráveis, tanto para o consumidor quanto para a instituição financeira.\n",
        "\n",
        "Um outro fator a ser considerado é a quantidade de falsos positivos, ou seja, aquelas vezes em que você tentou fazer uma compra e teve seu cartão bloqueado preventivamente - o que provavelmente gerou estresse e constrangimento.\n",
        "\n",
        "Por todos esses motivos, o investimento na área de detecção de fraudes por meio de Inteligência Artificial vem crescendo a cada ano, representando uma grande oportunidade em *Data Science*. \n",
        "\n",
        "Dispondo de grandes volumes de dados como base histórica, um algoritmo de machine learning apenas um pouco melhor que os anteriores já representa uma **economia de milhões de Reais**. E esse é o desafio: aprimorar cada vez mais o uso de algoritmos visando inibir ou evitar transações fraudulentas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HVmpIxQWT4Y",
        "colab_type": "text"
      },
      "source": [
        "## **Importando os Dados**\n",
        "\n",
        "Os dados que usaremos neste projeto foram disponibilizados por algumas empresas européias de cartão de crédito. O *dataset* representa as operações financeiras que aconteceram no período de dois dias, onde foram classificadas 492 fraudes em meio a quase 290 mil transações.\n",
        "\n",
        "Como você pode notar, este é um conjunto de dados extremamente desbalanceado, onde as fraudes representam **apenas 0,17% do total**.\n",
        "\n",
        "Outro detalhe interessante é que as *features* são todas numéricas, pois foram descaracterizadas (por restrições ligadas à privacidade e segurança). Assim, os nomes das colunas são representados por $[V1, V2, V3 \\dots, V28]$. \n",
        "\n",
        "<p align=center>\n",
        "<img src=\"https://image.freepik.com/free-vector/landing-page-concept-credit-card-payment_23-2148303916.jpg\" width=\"50%\"></p>\n",
        "\n",
        "[Na página original dos dados](https://www.kaggle.com/mlg-ulb/creditcardfraud) também é informado que as variáveis passaram por uma transformação conhecida como Análise de Componentes Principais (*Principal Component Analysis* - PCA).\n",
        "\n",
        "A PCA permite a redução da dimensionalidade enquanto mantém o maior número possível de informações. Para conseguir isso, o algoritmo encontra um conjunto novo de recursos - os chamados **componentes**.\n",
        "\n",
        "Esses componentes são em número menor ou igual às variáveis originais. No caso deste projeto, os componentes resultantes pela transformação da PCA são as próprias colunas $[V1, V2, V3 \\dots, V28]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NxUOfDOj2j8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importar o pacote pandas\n",
        "import pandas as pd\n",
        "\n",
        "# importar o pacote numpy\n",
        "import numpy as np\n",
        "\n",
        "# definir que o resultado aleatório sempre seja o mesmo\n",
        "np.random.seed(123)\n",
        "\n",
        "# caminho do dataset\n",
        "file_path = \"https://www.dropbox.com/s/hlx9qxh02zn228o/creditcard.csv?dl=1\"\n",
        "\n",
        "# importar os dados para um dataframe\n",
        "df = pd.read_csv(file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nF_Dhd81Cvq",
        "colab_type": "text"
      },
      "source": [
        "Com os dados importados para dentro de uma estrutura *Dataframe* - e não havendo a necessidade de mais nenhum ajuste ou configuração nesta etapa, pode-se iniciar uma análise exploratória dos dados a fim de preparar um modelo de *Machine Learning*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UtXyZ6stlSM",
        "colab_type": "text"
      },
      "source": [
        "## **Análise Exploratória**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_m48MQzOV47",
        "colab_type": "text"
      },
      "source": [
        "Vamos analisar as 5 primeiras entradas de nosso *Dataframe*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoyaQv-ZOZ_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verificar as 5 primeiras entradas do Dataframe\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4azXlXgQDpo",
        "colab_type": "text"
      },
      "source": [
        "A seguir iremos detalhar o significado das variáveis acima.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCqxiZ_jQL6t",
        "colab_type": "text"
      },
      "source": [
        "### **Dicionário de variáveis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qudXERKi_WbR",
        "colab_type": "text"
      },
      "source": [
        "As variáveis (também podemos chamá-las de colunas ou *features*) serão detalhadas abaixo, para nível de conhecimento de nosso *Dataframe*.\n",
        "\n",
        "Esta etapa tem por objetivo demostrar a situação inicial dos dados e permitir um entendimento de como os mesmos estão estruturados.\n",
        "1. `Time` - Número de segundos decorridos entre a transação da linha selecionada e a primeira transação no conjunto de dados.\n",
        "1. `V1 - V28` -  Resultado da redução de dimensionalidade pela transformação PCA, para proteger dados sensíveis e identidade de usuários.\n",
        "1. `Amount` - Valor da transação.\n",
        "1. `Class` - Se a transação for fraudulenta, será sinalizada por 1 (um). Caso contrário, será 0 (zero).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvVaxvJzPTQd",
        "colab_type": "text"
      },
      "source": [
        "Vamos analisar o total de variáveis e entradas que nosso *Dataframe* possui."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUbDV5Q4PjgQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verificar as variáveis e entradas do Dataframe\n",
        "print(f\"Variáveis:\\t {df.shape[1]}\")\n",
        "print(f\"Entradas:\\t {df.shape[0]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPx8NRjUS7it",
        "colab_type": "text"
      },
      "source": [
        "Veremos a seguir um resumo estatístico do *Dataframe*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XKrTaaLTIFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verificar o resumo do Dataframe\n",
        "df.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrPaCM69U8Rc",
        "colab_type": "text"
      },
      "source": [
        "Nessa análise podemos afirmar que o valor médio das transações (coluna *Amount*) foi de **U$$ 88.34**. Sendo assim, podemos verificar que as transações não possuíam valores altos.\n",
        "\n",
        "Em relação a coluna *Time*, podemos também afirmar que o maior tempo em relação à primeira transação foi de **172.792 segundos (48 horas de transações)**. Isso nos dá uma média de **99 transações por minuto**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVi6LdTW7w4",
        "colab_type": "text"
      },
      "source": [
        "Para criarmos um modelo de Machine Learning, nosso *Dataframe* não deve conter dados nulos. Vamos verificar se existe algum campo nessa condição. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9rzkRlrHS9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# verificar quantos dados nulos o Dataframe possui\n",
        "df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTJXaALfHfvO",
        "colab_type": "text"
      },
      "source": [
        "Como podemos verificar, nossas variáveis não possuem nenhum campo nulo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6TVC7Z9H0lL",
        "colab_type": "text"
      },
      "source": [
        "Vamos analisar nossa coluna alvo *Class*, onde exibe se a transação foi fraudulenta ou não."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNkZhsmMH8o5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imprimir a quantidade do tipo de transações no Dataframe\n",
        "print(df.Class.value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7iZAafxMdMm",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@markdown A maioria das transações foram lícitas. Observemos a baixa porcentagem de transações fraudulentas, juntamente com um gráfico para melhor comparação visual.\n",
        "print((df[df.Class == 1].shape[0] / df.shape[0]) * 100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM20ZY73Id4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importar as bibliotecas matplotlib e seaborn\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# plotar gráfico de barras para exibir visualmente as classes\n",
        "fig, ax = plt.subplots()\n",
        "sns.countplot('Class', data=df, ax=ax)\n",
        "plt.text(0, 305000, 'Lícitas X Fraudes',\n",
        "         fontsize=16, \n",
        "         color=\"#000000\",\n",
        "         weight='bold')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ysv7SftOi_R",
        "colab_type": "text"
      },
      "source": [
        "Vamos analisar graficamente a evolução das transações lícitas e ilícitas, para gerarmos insights em nossa avaliação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7114wN1mdMBG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(ncols=1, figsize=(10,5))\n",
        "\n",
        "x = df.Time[df.Class == 0]\n",
        "\n",
        "ax.hist(x, bins=30)\n",
        "\n",
        "hour_starts = []\n",
        "hour_names = [\"00:00\"]\n",
        "hour_increment = 0\n",
        "\n",
        "for i in range(0, 175000, 10800):\n",
        "  hour_increment = hour_increment + 3\n",
        "  hour_starts.append(i)\n",
        "  hour_names.append(\"{}:00\".format(hour_increment))\n",
        "\n",
        "ax.set_xticks(hour_starts)\n",
        "ax.set_xticklabels(hour_names)\n",
        "\n",
        "ax.text(0, 15000, 'Lícitas',\n",
        "         fontsize=16, \n",
        "         color=\"#000000\",\n",
        "         weight='bold')\n",
        "plt.xlabel('Tempo (horas)')\n",
        "plt.ylabel('Transações')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmh-WjBhWifj",
        "colab_type": "text"
      },
      "source": [
        "No gráfico anterior podemos afirmar que, entre as 21 e 24h de coletas de transações em nosso *Dataset*, ocorreram o maior número de transações lícitas simultâneas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxAh2iEJO6QP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(ncols=1, figsize=(10,5))\n",
        "\n",
        "x = df.Time[df.Class == 1]\n",
        "\n",
        "ax.hist(x, bins=30)\n",
        "\n",
        "hour_starts = []\n",
        "hour_names = [\"00:00\"]\n",
        "hour_increment = 0\n",
        "\n",
        "for i in range(0, 175000, 10800):\n",
        "  hour_increment = hour_increment + 3\n",
        "  hour_starts.append(i)\n",
        "  hour_names.append(\"{}:00\".format(hour_increment))\n",
        "\n",
        "ax.set_xticks(hour_starts)\n",
        "ax.set_xticklabels(hour_names)\n",
        "\n",
        "ax.text(0, 45, 'Fraudes',\n",
        "         fontsize=16, \n",
        "         color=\"#000000\",\n",
        "         weight='bold')\n",
        "plt.xlabel('Tempo (horas)')\n",
        "plt.ylabel('Transações')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBq83EejW5C6",
        "colab_type": "text"
      },
      "source": [
        "Já no gráfico a respeito das fraudes, podemos afirmar que, em torno das 12h iniciais, ocorreram o maior número de transações fraudulentas simultaneamente. Infelizmente não temos a coluna com o horário real, pois seria interessante para visualizarmos qual horário é o preferido para tentativa de fraudes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iByIpGHv9Yav",
        "colab_type": "text"
      },
      "source": [
        "Podemos verificar o relacionamento entre variáveis, utilizando um mapa de calor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua8k1rqKwRZl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criar um heatmap\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "sns.heatmap(df.corr(), linewidths=.2)\n",
        "ax.text(0, -0.5, 'Mapa de calor',\n",
        "         fontsize=16, \n",
        "         color=\"#000000\",\n",
        "         weight='bold')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSs-8MJL_7PW",
        "colab_type": "text"
      },
      "source": [
        "Com esse mapa de calor podemos verificar quais variáveis possuem total relação (cor mais clara) e nenhuma relação (cor mais escura). Na tabela abaixo podemos verificar as mesmas informações, de outra maneira, quanto mais próximo de 1, melhor a relação entre as variáveis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H44GKnhE_e4F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.corr().style.background_gradient(cmap='RdBu_r')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjJefNvyBAKs",
        "colab_type": "text"
      },
      "source": [
        "Nesse modo, podemos notar que a variável `Class` não possui correlação forte com as variáveis `V6, V7 e V9`, entre outras, com resultado abaixo de 0 (zero)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULe7z0jZt0EH",
        "colab_type": "text"
      },
      "source": [
        "## **Preparação dos Dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbgydYcfBlap",
        "colab_type": "text"
      },
      "source": [
        "Nessa etapa, iremos preparar nossos dados para que possamos construir o modelo de Machine Learning. Iniciaremos normalizando os dados das colunas `Time` e `Amount`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4DK9z-nN7a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importar o pacote StandardScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# criar uma cópia do Dataframe original\n",
        "df_copy = df.copy()\n",
        "\n",
        "# instanciar o pacote para normalizar\n",
        "std_scaler = StandardScaler()\n",
        "\n",
        "# remover as colunas da cópia do Dataframe, para recriarmos no próximo passo\n",
        "df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "\n",
        "# recriar as colunas, normalizando as mesmas\n",
        "df_copy['Time'] = std_scaler.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
        "df_copy['Amount'] = std_scaler.fit_transform(df['Time'].values.reshape(-1, 1))\n",
        "\n",
        "# ver as primeiras entradas do Dataframe alterado\n",
        "df_copy.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfKpdGoRuF5T",
        "colab_type": "text"
      },
      "source": [
        "Nosso próximo passo consiste dividir nossos dados entre treino e teste, para utilizarmos na construção de nosso modelo de classificação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu5OczjIxzLD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importar a função train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# separar variáveis X e y\n",
        "X = df_copy.drop('Class', axis=1)\n",
        "y = df['Class']\n",
        "\n",
        "# dividir o dataset entre treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2exSg0gyhrZ",
        "colab_type": "text"
      },
      "source": [
        "Vamos verificar como ocorreu nossa divisão."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N3pvgfMykuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f\"Nosso Dataset contém {df_copy.shape[1]} variáveis e {df_copy.shape[0]} colunas.\")\n",
        "print(f\"Nossos dados de treino são: X = {X_train.shape} e y = {y_train.shape}\")\n",
        "print(f\"Nossos dados de teste são: X = {X_test.shape} e y = {y_test.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LO-EpHvFzqMd",
        "colab_type": "text"
      },
      "source": [
        "Notamos que nossos dados foram divididos de acordo com nosso parâmetro `test_size`: 80% de dados para treino e 20% de dados para teste."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WcU5w1YfiYyg"
      },
      "source": [
        "## **Modelos de Machine Learning - Dados Desbalanceados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "9X8GmgemiYyl"
      },
      "source": [
        "Após a análise de nosso *Dataframe*, iremos construir modelos de classificação para validar qual terá melhor performance em nossa previsão entre transações lícitas ou fraudulentas. Os modelos escolhidos foram **Regressão Logística, Decision Trees e KNN**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "klrtyAGpiYyo"
      },
      "source": [
        "### Regressão Logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_cXDjE3xiYyr",
        "colab": {}
      },
      "source": [
        "# importar o modelo LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# instanciar o modelo\n",
        "model_logistic_regression_unbalanced = LogisticRegression()\n",
        "\n",
        "# treinamento do modelo\n",
        "model_logistic_regression_unbalanced.fit(X_train, y_train)\n",
        "\n",
        "# fazer previsões em cima de novos dados\n",
        "y_pred_logistic_regression_unbalanced = model_logistic_regression_unbalanced.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rwU7E2LRiYy4"
      },
      "source": [
        "### Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O8EuCfaDiYy6",
        "colab": {}
      },
      "source": [
        "# importar o modelo DecisionTreeClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# instanciar o modelo e escolher os hyperparameters\n",
        "model_decision_tree_unbalanced = DecisionTreeClassifier(max_depth=4, criterion=\"entropy\")\n",
        "\n",
        "# treinamento do modelo\n",
        "model_decision_tree_unbalanced.fit(X_train, y_train)\n",
        "\n",
        "# fazer previsões em cima de novos dados\n",
        "y_pred_decision_tree_unbalanced = model_decision_tree_unbalanced.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3ytLQjKEiYzF"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "whPX014EiYzH",
        "colab": {}
      },
      "source": [
        "# importar o pacote neighbors\n",
        "from sklearn import neighbors\n",
        "\n",
        "# instanciar o modelo e escolher os hyperparameters\n",
        "model_knn_unbalanced = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# treinamento do modelo\n",
        "model_knn_unbalanced.fit(X_train, y_train)\n",
        "\n",
        "# fazer previsões em cima de novos dados\n",
        "y_pred_knn_unbalanced = model_knn_unbalanced.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HI6rZWs6hlUz",
        "colab_type": "text"
      },
      "source": [
        "## **Balanceamento dos Dados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIEe2nW3z5rO",
        "colab_type": "text"
      },
      "source": [
        "Lembramos que no início do projeto verificamos a proporção de atividades lícitas e fraudes, onde a mesma é muito desigual. Para  melhor performance de nosso modelo, iremos balancear o conjunto de dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5szeOG-0keH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importar a função RandomUnderSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "# técnica de balanceamento Under-sampling\n",
        "random_under_sampler = RandomUnderSampler()\n",
        "X_random_under_sampler, y_random_under_sampler = random_under_sampler.fit_sample(X_train, y_train)\n",
        "\n",
        "# ver como resultou o balanceamento das classes\n",
        "print(pd.Series(y_random_under_sampler).value_counts())\n",
        "\n",
        "# plotar a nova distribuição de classes\n",
        "sns.countplot(y_random_under_sampler)\n",
        "plt.text(-0.5, 425, 'Lícitas X Fraudes',\n",
        "         fontsize=16, \n",
        "         color=\"#000000\",\n",
        "         weight='bold')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcYN27Uu1nRp",
        "colab_type": "text"
      },
      "source": [
        "Agora com os dados balanceados, podemos comparar os mapas de calor pré e pós balanceamento, para verificarmos se houve alguma diferença."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDclLGzevEWX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criar Dataframes pré e pós balanceamento\n",
        "corr = X_train.corr()\n",
        "corr_random_under_sampler = pd.DataFrame(X_random_under_sampler).corr()\n",
        "\n",
        "# criar os mapas de calor contendo os dados de treino pré e pós balanceamento\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, figsize = (22,12))\n",
        "\n",
        "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, linewidths=.1, cmap=\"coolwarm\", ax=ax[0])\n",
        "sns.heatmap(corr_random_under_sampler, xticklabels=corr.columns, yticklabels=corr.columns, linewidths=.1, cmap=\"coolwarm\", ax=ax[1])\n",
        "\n",
        "ax[0].text(0, -0.5, 'Pré balanceamento',\n",
        "         fontsize=16, \n",
        "         color=\"#000000\",\n",
        "         weight='bold')\n",
        "\n",
        "ax[1].text(0, -0.5, 'Pós balanceamento',\n",
        "         fontsize=16, \n",
        "         color=\"#000000\",\n",
        "         weight='bold')\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uyYEZ2S3VW0",
        "colab_type": "text"
      },
      "source": [
        "Analisando os mapas de calor acima, notamos que após o balanceamento surgiram variáveis que possuem melhor relação entre elas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJNH5qcjRxfX",
        "colab_type": "text"
      },
      "source": [
        "## **Modelos de Machine Learning - Dados Balanceados**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95dH0pWEn65y",
        "colab_type": "text"
      },
      "source": [
        "Após o balanceamento de nosso *Dataframe*, iremos reconstruir os mesmos modelos de classificação para validar qual terá melhor performance em nossa previsão entre transações lícitas ou fraudulentas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GczDwA1ftw2E",
        "colab_type": "text"
      },
      "source": [
        "### Regressão Logística"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riP1NpuBstV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instanciar o modelo\n",
        "model_logistic_regression_balanced = LogisticRegression()\n",
        "\n",
        "# treinamento do modelo\n",
        "model_logistic_regression_balanced.fit(X_random_under_sampler, y_random_under_sampler)\n",
        "\n",
        "# fazer previsões em cima de novos dados\n",
        "y_pred_logistic_regression_balanced = model_logistic_regression_balanced.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UShiyLoP2jgy",
        "colab_type": "text"
      },
      "source": [
        "### Decision Trees"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwtyT1ar2ls4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instanciar o modelo e escolher os hyperparameters\n",
        "model_decision_tree_balanced = DecisionTreeClassifier(max_depth=4, criterion=\"entropy\")\n",
        "\n",
        "# treinamento do modelo\n",
        "model_decision_tree_balanced.fit(X_random_under_sampler, y_random_under_sampler)\n",
        "\n",
        "# fazer previsões em cima de novos dados\n",
        "y_pred_decision_tree_balanced = model_decision_tree_balanced.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qWwKO1Kt3QW",
        "colab_type": "text"
      },
      "source": [
        "### KNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtC2rE3ws-6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instanciar o modelo e escolher os hyperparameters\n",
        "model_knn_balanced = neighbors.KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# treinamento do modelo\n",
        "model_knn_balanced.fit(X_random_under_sampler, y_random_under_sampler)\n",
        "\n",
        "# fazer previsões em cima de novos dados\n",
        "y_pred_knn_balanced = model_knn_balanced.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e4ENOTYSUXi",
        "colab_type": "text"
      },
      "source": [
        "## **Avaliar o desempenho dos modelos**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4zjQ-PT5lIG",
        "colab_type": "text"
      },
      "source": [
        "Nessa etapa iremos avaliar o desempenho dos 3 modelos utilizados para verificar qual deles será a melhor escolha para previsão de transações lícitas ou fraudulentas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9cRIQzV4R2l",
        "colab_type": "text"
      },
      "source": [
        "### Regressão Logística - Dados desbalanceados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw_BToaat8Hs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importar a função classification_report\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# imprimir relatório de classificação\n",
        "print(classification_report(y_test, y_pred_logistic_regression_unbalanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_n30fAbYx5Vq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# instalar skplt\n",
        "!pip install -q scikit-plot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqL7dT7GvD02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importar a função skplt\n",
        "import scikitplot as skplt\n",
        "\n",
        "# criar uma matriz de confusão\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_logistic_regression_unbalanced, normalize=True, cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrvI_HXrzMop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# importar a função accuracy_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# imprimir a acurácia do modelo\n",
        "result_accuracy_logistic_regression_unbalanced = accuracy_score(y_test, y_pred_logistic_regression_unbalanced)\n",
        "print(\"Acurácia: {:.4f}\\n\".format(result_accuracy_logistic_regression_unbalanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Y2F5X2hk8sx",
        "colab": {}
      },
      "source": [
        "# importar a função auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# imprimir a área sob a curva\n",
        "result_auc_logistic_regression_unbalanced = roc_auc_score(y_test, y_pred_logistic_regression_unbalanced)\n",
        "print(\"AUC: {:.4f}\\n\".format(result_auc_logistic_regression_unbalanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OsO--f3-k2D3"
      },
      "source": [
        "### Regressão Logística - Dados balanceados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kGZW2D8Ck2D6",
        "colab": {}
      },
      "source": [
        "# imprimir relatório de classificação\n",
        "print(classification_report(y_test, y_pred_logistic_regression_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g2iZ9Eaqk2EJ",
        "colab": {}
      },
      "source": [
        "# criar uma matriz de confusão\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_logistic_regression_balanced, normalize=True, cmap='Reds')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OsKaCMwDk2EU",
        "colab": {}
      },
      "source": [
        "# imprimir a acurácia do modelo\n",
        "result_accuracy_logistic_regression_balanced = accuracy_score(y_test, y_pred_logistic_regression_balanced)\n",
        "print(\"Acurácia: {:.4f}\\n\".format(result_accuracy_logistic_regression_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Hv92Cl_Wk2Ec",
        "colab": {}
      },
      "source": [
        "# imprimir a área sob a curva\n",
        "result_auc_logistic_regression_balanced = roc_auc_score(y_test, y_pred_logistic_regression_balanced)\n",
        "print(\"AUC: {:.4f}\\n\".format(result_auc_logistic_regression_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwRrft9W4WiA",
        "colab_type": "text"
      },
      "source": [
        "### Decision Trees - Dados desbalanceados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZoSFii129px",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imprimir relatório de classificação\n",
        "print(classification_report(y_test, y_pred_decision_tree_unbalanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-mApTuD3Em-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criar uma matriz de confusão\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_decision_tree_unbalanced, normalize=True, cmap='Blues')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42QZFsCy3RfY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imprimir a acurácia do modelo\n",
        "result_accuracy_decision_tree_unbalanced = accuracy_score(y_test, y_pred_decision_tree_unbalanced)\n",
        "print(\"Acurácia: {:.4f}\\n\".format(result_accuracy_decision_tree_unbalanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9rhENUn3MJW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imprimir a área sob a curva\n",
        "result_auc_decision_tree_unbalanced = roc_auc_score(y_test, y_pred_decision_tree_unbalanced)\n",
        "print(\"AUC: {:.4f}\\n\".format(result_auc_decision_tree_unbalanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k8uF_w-4kzLh"
      },
      "source": [
        "### Decision Trees - Dados balanceados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aK15j2PVkzLi",
        "colab": {}
      },
      "source": [
        "# imprimir relatório de classificação\n",
        "print(classification_report(y_test, y_pred_decision_tree_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0TmnOzZekzLq",
        "colab": {}
      },
      "source": [
        "# criar uma matriz de confusão\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_decision_tree_balanced, normalize=True, cmap='Blues')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mZQMBYfykzLz",
        "colab": {}
      },
      "source": [
        "# imprimir a acurácia do modelo\n",
        "result_accuracy_decision_tree_balanced = accuracy_score(y_test, y_pred_decision_tree_balanced)\n",
        "print(\"Acurácia: {:.4f}\\n\".format(result_accuracy_decision_tree_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sQjHcmvJkzL7",
        "colab": {}
      },
      "source": [
        "# imprimir a área sob a curva\n",
        "result_auc_decision_tree_balanced = roc_auc_score(y_test, y_pred_decision_tree_balanced)\n",
        "print(\"AUC: {:.4f}\\n\".format(result_auc_decision_tree_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XK6lA6V4YbC",
        "colab_type": "text"
      },
      "source": [
        "### KNN - Dados desbalanceados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JVdDDfQ3yXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imprimir relatório de classificação\n",
        "print(classification_report(y_test, y_pred_knn_unbalanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa1RKl5P32uL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# criar uma matriz de confusão\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_knn_unbalanced, normalize=True, cmap='Oranges')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejVIIk3T3_tr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imprimir a acurácia do modelo\n",
        "result_accuracy_knn_unbalanced = accuracy_score(y_test, y_pred_knn_unbalanced)\n",
        "print(\"Acurácia: {:.4f}\\n\".format(result_accuracy_knn_unbalanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYR9afyU37kP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imprimir a área sob a curva\n",
        "result_auc_knn_unbalanced = roc_auc_score(y_test, y_pred_knn_unbalanced)\n",
        "print(\"AUC: {:.4f}\\n\".format(result_auc_knn_unbalanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "D6Q_1aMLkv3p"
      },
      "source": [
        "### KNN - Dados balanceados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ax_2V5a3kv3v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "bb85e558-281e-4f91-d9b3-1eef065916c7"
      },
      "source": [
        "# imprimir relatório de classificação\n",
        "print(classification_report(y_test, y_pred_knn_balanced))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.99     56847\n",
            "           1       0.07      0.93      0.13       115\n",
            "\n",
            "    accuracy                           0.97     56962\n",
            "   macro avg       0.53      0.95      0.56     56962\n",
            "weighted avg       1.00      0.97      0.99     56962\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dHBhLBVykv3-",
        "colab": {}
      },
      "source": [
        "# criar uma matriz de confusão\n",
        "skplt.metrics.plot_confusion_matrix(y_test, y_pred_knn_balanced, normalize=True, cmap='Oranges')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_ajEg1Ttkv4P",
        "colab": {}
      },
      "source": [
        "# imprimir a acurácia do modelo\n",
        "result_accuracy_knn_balanced = accuracy_score(y_test, y_pred_knn_balanced)\n",
        "print(\"Acurácia: {:.4f}\\n\".format(result_accuracy_knn_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ZAQRwbKIkv4Y",
        "colab": {}
      },
      "source": [
        "# imprimir a área sob a curva\n",
        "result_auc_knn_balanced = roc_auc_score(y_test, y_pred_knn_balanced)\n",
        "print(\"AUC: {:.4f}\\n\".format(result_auc_knn_balanced))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Bj7zRZMSfO7",
        "colab_type": "text"
      },
      "source": [
        "## **Conclusão**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cdct0l_r7JN6",
        "colab_type": "text"
      },
      "source": [
        "Comparando os três modelos utilizados, podemos chegar no seguinte resultado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0ar1Vza7Nhl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_percents(value):\n",
        "  return \"{:.4f}\".format(value)\n",
        "\n",
        "# criar um dicionário com dados para comparação\n",
        "results = {'Modelos': ['Regressão Logística', 'Decision Trees', 'KNN'],\n",
        "           'Acurácias desbalanceadas': [format_percents(result_accuracy_logistic_regression_unbalanced), format_percents(result_accuracy_decision_tree_unbalanced), format_percents(result_accuracy_knn_unbalanced)],\n",
        "           'Acurácias balanceadas': [format_percents(result_accuracy_logistic_regression_balanced), format_percents(result_accuracy_decision_tree_balanced), format_percents(result_accuracy_knn_balanced)],\n",
        "           'AUCs desbalanceadas': [format_percents(result_auc_logistic_regression_unbalanced), format_percents(result_auc_decision_tree_unbalanced), format_percents(result_auc_knn_unbalanced)],\n",
        "           'AUCs balanceadas': [format_percents(result_auc_logistic_regression_balanced), format_percents(result_auc_decision_tree_balanced), format_percents(result_auc_knn_balanced)]}\n",
        "\n",
        "# converter em DataFrame\n",
        "compare = pd.DataFrame(data=results)\n",
        "\n",
        "# importar a função data_table\n",
        "from google.colab import data_table\n",
        "\n",
        "# imprimir a tabela de comparação\n",
        "data_table.DataTable(compare, include_index=False, num_rows_per_page=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brQ5HvQOknYo",
        "colab_type": "text"
      },
      "source": [
        "Avaliando os três modelos propostos, podemos observar que as métricas de acurácia e AUC do modelo *KNN* foram maiores que os outros modelos avaliados.\n",
        "\n",
        "Se comparamos os valores dos modelos desbalanceados e balanceados, podemos notar nos gráficos *Normalized Confusion Matrix* (ou na tabela *Classification Report, coluna recall*) anteriores que, quando utilizado os dados desbalanceados, as métricas para previsão de transações lícitas chegam a 100% de desempenho, mas para as transações fraudulentas temos um fraco desempenho. Já com os dados balanceados, temos um melhor desempenho tanto nas transações lícitas como nas fraudulentas. Sendo assim, notamos com essa comparação a suma importância que a etapa de balanceamento de dados tem sobre nossos modelos preditivos.\n",
        "\n",
        "Podemos comparar também na tabela anterior que, as acurácias desbalanceadas são próximo de 100%, mas que a métrica AUC desbalanceada é bem inferior a métrica AUC balanceada, confirmando ainda mais nossa afirmação de que o balanceamento de dados é vital para o sucesso de nossos modelos preditivos.\n",
        "\n",
        "Como citado no início desse projeto, a melhora desse algoritmo já proporciona uma segurança maior durante o uso de cartões de crédito, visto que fica mais preciso a sua eficácia.\n",
        "\n",
        "Obrigado pela leitura e me acompanhe no [LinkedIn](https://www.linkedin.com/in/rodrigomariamorgao/) e no [Medium](https://medium.com/@rodrigomariamorgao) para outros artigos e análises. Abraço!"
      ]
    }
  ]
}